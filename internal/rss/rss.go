package rss

import (
    "log"
    "net/http"
    "strings"
    "sync"
    "time"
    "unicode"

    "github.com/mmcdole/gofeed"
    "rss2tg/internal/storage"
)
 
type MessageHandler func(title, url, group string, pubDate time.Time, matchedKeywords []string) error

type Manager struct {
    feeds          []*Feed
    db             *storage.Storage
    messageHandler MessageHandler
    mu             sync.Mutex
}

type Feed struct {
    URLs            []string
    Interval        time.Duration
    Keywords        []string
    Group           string
    AllowPartMatch  bool      // æ˜¯å¦å…è®¸éƒ¨åˆ†åŒ¹é…
    Enabled         bool      // æ˜¯å¦å¯ç”¨æ­¤è®¢é˜…
    ticker          *time.Ticker
    stopChan        chan struct{}
}

type Config struct {
    URLs            []string
    Interval        int
    Keywords        []string
    Group           string
    AllowPartMatch  bool      // æ˜¯å¦å…è®¸éƒ¨åˆ†åŒ¹é…
    Enabled         bool      // æ˜¯å¦å¯ç”¨æ­¤è®¢é˜…
}

func NewManager(configs []Config, db *storage.Storage) *Manager {
    manager := &Manager{
        db: db,
    }
    manager.UpdateFeeds(configs)
    return manager
}

func (m *Manager) SetMessageHandler(handler MessageHandler) {
    m.messageHandler = handler
}

func (m *Manager) UpdateFeeds(configs []Config) {
    m.mu.Lock()
    defer m.mu.Unlock()

    // åœæ­¢æ‰€æœ‰ç°æœ‰çš„feedè½®è¯¢å™¨
    for _, feed := range m.feeds {
        if feed.stopChan != nil {
            close(feed.stopChan)
        }
    }

    // åˆ›å»ºæ–°çš„feeds
    m.feeds = make([]*Feed, len(configs))
    for i, config := range configs {
        m.feeds[i] = &Feed{
            URLs:           config.URLs,
            Interval:       time.Duration(config.Interval) * time.Second,
            Keywords:       config.Keywords,
            Group:          config.Group,
            AllowPartMatch: config.AllowPartMatch,  // æ·»åŠ éƒ¨åˆ†åŒ¹é…é…ç½®
            Enabled:        config.Enabled,         // æ·»åŠ å¯ç”¨çŠ¶æ€é…ç½®
            stopChan:       make(chan struct{}),
        }
    }

    // å¯åŠ¨æ–°çš„feedè½®è¯¢å™¨ï¼ˆä»…å¯ç”¨çš„è®¢é˜…ï¼‰
    for _, feed := range m.feeds {
        if feed.Enabled {
            go m.pollFeed(feed)
        } else {
            log.Printf("è®¢é˜…å·²ç¦ç”¨ï¼Œè·³è¿‡å¯åŠ¨è½®è¯¢å™¨: %v", feed.URLs)
        }
    }
}

func (m *Manager) Start() {
    log.Println("RSSç®¡ç†å™¨å·²å¯åŠ¨")
}

func (m *Manager) pollFeed(feed *Feed) {
    feed.ticker = time.NewTicker(feed.Interval)
    defer feed.ticker.Stop()

    for {
        select {
        case <-feed.ticker.C:
            if !feed.Enabled {
                log.Printf("è®¢é˜…å·²ç¦ç”¨ï¼Œè·³è¿‡è½®è¯¢: %v", feed.URLs)
                continue
            }
            for _, url := range feed.URLs {
                m.checkFeed(feed, url)
            }
        case <-feed.stopChan:
            log.Printf("åœæ­¢feedè½®è¯¢å™¨: %v", feed.URLs)
            return
        }
    }
}

func (m *Manager) checkFeed(feed *Feed, url string) {
    // å¼€å§‹æ£€æŸ¥Feedçš„æ—¥å¿—
    log.Printf("ğŸ” å¼€å§‹æ£€æŸ¥Feed: %s", url)
    
    fp := gofeed.NewParser()
    
    // åˆ›å»ºè‡ªå®šä¹‰çš„ HTTP å®¢æˆ·ç«¯
    client := &http.Client{
        Timeout: 30 * time.Second,
    }
    
    // åˆ›å»ºè‡ªå®šä¹‰çš„è¯·æ±‚
    req, err := http.NewRequest("GET", url, nil)
    if err != nil {
        log.Printf("âŒ åˆ›å»ºè¯·æ±‚å¤±è´¥ %s: %v", url, err)
        return
    }
    
    // æ·»åŠ æµè§ˆå™¨æ ‡è¯†å’Œå…¶ä»–å¿…è¦çš„å¤´ä¿¡æ¯
    req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    req.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
    req.Header.Set("Accept-Language", "zh-CN,zh;q=0.9,en;q=0.8")
    req.Header.Set("Connection", "keep-alive")
    req.Header.Set("Upgrade-Insecure-Requests", "1")
    
    // ä½¿ç”¨è‡ªå®šä¹‰å®¢æˆ·ç«¯è§£æ Feed
    fp.Client = client
    parsedFeed, err := fp.ParseURL(url)
    if err != nil {
        log.Printf("âŒ è§£æFeedå¤±è´¥ %s: %v", url, err)
        return
    }

    // ç»Ÿè®¡ä¿¡æ¯
    totalArticles := len(parsedFeed.Items)
    newArticles := 0
    matchedArticles := 0
    
    log.Printf("ğŸ“Š FeedåŒ…å« %d ç¯‡æ–‡ç« ", totalArticles)
    
    if totalArticles == 0 {
        log.Printf("ğŸ“ Feedæ£€æŸ¥å®Œæˆ: %s - æ— æ–°æ–‡ç« ", url)
        return
    }

    for _, item := range parsedFeed.Items {
        matchedKeywords := m.matchKeywords(item, feed)
        
        // å¦‚æœæ–‡ç« æœªæ›¾å‘é€è¿‡ï¼Œè¯´æ˜æ˜¯æ–°æ–‡ç« 
        if !m.db.WasSent(item.Link) {
            newArticles++
        }
        
        // ä¿®æ”¹åˆ¤æ–­é€»è¾‘ï¼šå¦‚æœæ²¡æœ‰é…ç½®å…³é”®è¯æˆ–è€…åŒ¹é…åˆ°äº†å…³é”®è¯ï¼Œå°±å‘é€æ¶ˆæ¯
        if len(matchedKeywords) > 0 {
            matchedArticles++
            
            // æ ¹æ®URLè·å–ç®€çŸ­çš„RSSæºåç§°ç”¨äºæ—¥å¿—
            var logMessage string
            var keywordInfo string
            
            if matchedKeywords[0] == "__NO_KEYWORDS__" {
                logMessage = "âœ… å‘ç°æ–°æ–‡ç« "
                keywordInfo = "æ— å…³é”®è¯è¿‡æ»¤"
                // ä½¿ç”¨ç©ºæ•°ç»„ï¼Œè¿™æ ·åœ¨æ¶ˆæ¯ä¸­å°±ä¸ä¼šæ˜¾ç¤ºå…³é”®è¯
                matchedKeywords = []string{}
            } else {
                logMessage = "ğŸ¯ å‘ç°åŒ¹é…æ–‡ç« "
                keywordInfo = strings.Join(matchedKeywords, ", ")
            }
            
            log.Printf("%s: [%s] æ ‡é¢˜: %s | åŒ¹é…å…³é”®è¯: %s", logMessage, url, item.Title, keywordInfo)
            
            if err := m.messageHandler(item.Title, item.Link, feed.Group, *item.PublishedParsed, matchedKeywords); err != nil {
                log.Printf("âŒ å‘é€æ¶ˆæ¯å¤±è´¥: %v", err)
            } else {
                log.Printf("âœ… æ¶ˆæ¯å‘é€æˆåŠŸ: %s", item.Title)
                m.db.MarkAsSent(item.Link)
            }
        } else {
            // å¦‚æœæ˜¯æ–°æ–‡ç« ä½†æœªåŒ¹é…å…³é”®è¯
            if !m.db.WasSent(item.Link) {
                log.Printf("ğŸ“„ æ–°æ–‡ç« æœªåŒ¹é…å…³é”®è¯: [%s] %s", url, item.Title)
            }
        }
    }
    
    // è¾“å‡ºFeedæ£€æŸ¥æ‘˜è¦
    log.Printf("ğŸ“ Feedæ£€æŸ¥å®Œæˆ: %s | æ€»æ–‡ç« : %d, æ–°æ–‡ç« : %d, åŒ¹é…æ–‡ç« : %d", 
        url, totalArticles, newArticles, matchedArticles)
}

// normalizeText æ ‡å‡†åŒ–æ–‡æœ¬ï¼Œå¤„ç†ç‰¹æ®Šå­—ç¬¦å’Œç©ºç™½
func normalizeText(text string) string {
    // 1. è½¬æ¢ä¸ºå°å†™
    text = strings.ToLower(text)
    
    // 2. æ›¿æ¢å¸¸è§çš„ç‰¹æ®Šå­—ç¬¦ç»„åˆ
    replacements := map[string]string{
        "c++": "cpp",
        "c#": "csharp",
        ".net": "dotnet",
    }
    
    for old, new := range replacements {
        text = strings.ReplaceAll(text, old, new)
    }
    
    // 3. æ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•°å­—å’Œç©ºæ ¼
    var result strings.Builder
    for _, ch := range text {
        if unicode.IsLetter(ch) || unicode.IsNumber(ch) || unicode.IsSpace(ch) {
            result.WriteRune(ch)
        } else {
            // ç”¨ç©ºæ ¼æ›¿æ¢ç‰¹æ®Šå­—ç¬¦
            result.WriteRune(' ')
        }
    }
    
    // 4. è§„èŒƒåŒ–ç©ºç™½å­—ç¬¦
    return strings.Join(strings.Fields(result.String()), " ")
}

// isWordMatch æ£€æŸ¥å•è¯æ˜¯å¦å®Œå…¨åŒ¹é…
func isWordMatch(text, keyword string) bool {
    words := strings.Fields(text)
    for _, word := range words {
        if word == keyword {
            return true
        }
    }
    return false
}

// contains æ£€æŸ¥å­—ç¬¦ä¸²åˆ‡ç‰‡æ˜¯å¦åŒ…å«ç‰¹å®šå­—ç¬¦ä¸²
func contains(slice []string, str string) bool {
    for _, v := range slice {
        if v == str {
            return true
        }
    }
    return false
}

func (m *Manager) matchKeywords(item *gofeed.Item, feed *Feed) []string {
    if m.db.WasSent(item.Link) {
        return nil
    }

    if len(feed.Keywords) == 0 {
        // å¦‚æœæ²¡æœ‰é…ç½®å…³é”®è¯ï¼Œè¿”å›ä¸€ä¸ªç‰¹æ®Šæ ‡è®°
        return []string{"__NO_KEYWORDS__"}
    }

    // æ ‡å‡†åŒ–æ–‡æœ¬
    normalizedTitle := normalizeText(item.Title)
    normalizedDesc := normalizeText(item.Description)
    
    var matched []string
    
    // æ£€æŸ¥æ¯ä¸ªå…³é”®è¯
    for _, keyword := range feed.Keywords {
        // æ ‡å‡†åŒ–å…³é”®è¯
        normalizedKeyword := normalizeText(keyword)
        
        // é¦–å…ˆå°è¯•å®Œæ•´è¯åŒ¹é…
        if isWordMatch(normalizedTitle, normalizedKeyword) {
            if !contains(matched, keyword) {
                matched = append(matched, keyword)
            }
            continue
        }
        
        if isWordMatch(normalizedDesc, normalizedKeyword) {
            if !contains(matched, keyword) {
                matched = append(matched, keyword)
            }
            continue
        }
        
        // å¦‚æœå…è®¸éƒ¨åˆ†åŒ¹é…ä¸”æ²¡æœ‰æ‰¾åˆ°å®Œæ•´åŒ¹é…ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
        if feed.AllowPartMatch {
            if strings.Contains(normalizedTitle, normalizedKeyword) {
                if !contains(matched, keyword) {
                    matched = append(matched, keyword)
                }
            } else if strings.Contains(normalizedDesc, normalizedKeyword) {
                if !contains(matched, keyword) {
                    matched = append(matched, keyword)
                }
            }
        }
    }

    return matched
}
